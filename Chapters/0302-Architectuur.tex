\chapter{Architectuur}\label{ch:Architectuur}

Om inzicht te verkrijgen in potentiÃ«le kwetsbaarheden in de projecten van Eaglescience moet er een applicatie worden ontworpen die analyses kan uitvoeren op het moment dat er veranderingen worden aangebracht in deze projecten. Daarnaast moet de applicatie in staat zijn deze analyses uit te voeren op een periodieke basis.
Op het moment van schrijven wordt er binnen Eaglescience ontwikkeld in de talen Scala en TypeScript, maar de verwachting is dat er in de toekomst een mogelijkheid bestaat dat dit uitgebreid gaat worden. Daarnaast zijn deze twee talen niet de enige twee platformen binnen de stack, maar wordt er ook gebruik gemaakt van docker met daarbij verschillende images die ook kwetsbaarheden kunnen bevatten. Dit ontwerp voorziet niet in de mogelijkheid om deze toekomstige platformen (als Docker) te kunnen scannen, echter zal het wel de mogelijkheid bieden om deze op een relatief makkelijke manier later toe te voegen. De selectie van deze toekomstige tool moet wel de mogelijkheid bieden om te voorzien in de data beschreven in het interne datamodel.

Analyses worden uitgevoerd op module niveau, hier zijn in basis twee redenen voor. Ten eerste is een module binnen een Eaglescience project een afgeschermd onderdeel dat een eigen platform benut. Ten tweede kunnen er op module niveau veranderingen worden verwacht ten opzichte van dependency declaraties.

Als de architectuur wordt gebasseerd op het datamodel kan er vervolgens worden gekeken welke componenten en technieken er nodig zijn om het datamodel functioneeel te krijgen.

\section{Datamodel}\label{sec:datamodel}
Om de gebruiker in staat te stellen om een gedegen keuze te maken om over te gaan op het updaten van de applicatie is een zo actueel mogelijk beeld nodig van de huidige situatie omtrent kwetsbaarheden in een project. Om deze informatie kunnen bieden is er gekozen om dit te bieden op twee niveau's en dus door middel van twee datamodellen.
Het eerste datamodel is onderdeel van de SOUP-API en wordt hieronder verder refereert als het interne datamodel. Daarnaast is er een model dat binnen de Portal gebruikt wordt voor het opslaan van samengevatte gegevens verder benoemd als het Portalmodel.

%TODO: Kijken of er een ranking high ,medium etc aanwezig is. enhoe deze is opgebouwd.
\subsection{Interne datamodel}\label{subsec:interne-datamodel}
Het interne datamodel is opgebouwd op basis van de data die wordt verkregen van de in het onderzoek gevonden OWASP tools. Hieruit kan worden gedestileerd welke gegevens daadwerkelijk nodig zijn voor de functionaliteit die wordt verwacht binnen Eaglescience. Het in figuur~\ref{fig:SOUP-SoupApiDm} getoonde model laat deze destillatie zien. Centraal in het datamodel staat de analyse. De analyse is aan modules gekoppeld omdat de rapportages uit de SCA tooling gebasseerd zijn op modules en niet op projecten. Het project is een verzameling modules dat in zijn geheel een applicatie vormt. De analyse zelf is opgebouwd uit de dependency files, welke opgeslagen worden om in de toekomst periodieke analyses uit te kunnen voeren tot er een nieuwe analyse is. Ook worden alle dependencies opgeslagen waarin gevonden vulnarabilities en bewijs worden opgeslagen.

\begin{figure}[H]
    \myfloatalign
    \includegraphics[width=12cm]{gfx/SOUPAPI-SOUPAPI DM}
    \caption{Intern Datamodel}
    \label{fig:SOUP-SoupApiDm}
\end{figure}

Hieronder wordt iedere entiteit beschreven met daarin het attribuut, het datatype en de reden voor het opslaan van deze data, waarbij geldt dat voor iedere entititeit de volgende attributen standaard zijn \_id, \_createdAt en \_updatedAt opgeslagen.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    \_id & String & unique primary key\\
    \_createdAt & DateTime & timestamp aanmaken van record\\
    \_updatedAt & DateTime & timestampt wijzigen van record\\

\end{tabular}
%TODO dit is leidend datamodel bijwerken.
\subsubsection{Project}\label{subsubsec:project}
In deze entititeit worden de basisgegevens van de projecten opgeslagen als ook de relaties met de voor ieder project aanwezige modulen.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    projectSettings & String & referentie naar projectsettings\\
    name & String & naam van het project\\
    modules & Seq[String] & bij project horende modules\\

\end{tabular}
\subsubsection{Projectsettings}\label{subsubsec:projectsettings}
Deze enititeit geeft de mogelijkheid tot het opslaan van project specifieke instellingen met betrekking tot de SOUP API\@.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    scaninterval  & String & aantal dagen tussen analyses\\
\end{tabular}

\subsubsection{Module}\label{subsubsec:module}
De module is een op zichzelf staand onderdeel van de applicatie geisoleerd door een platform en de specifieke functie. Er kunnen meerdere modules in een project zitten.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    name  & String & naam van de module\\
    platform  & String & platform waar de module op geschreven is \\
    analyses  & Seq[String] & reverentie naar alle analyses die gedaan zijn op de module\\
\end{tabular}

\subsubsection{Analysis}\label{subsubsec:analysis}
Een analyse herbergt alle bekende informatie over een module op het moment van de analyse. De dependencies die hier opgeslagen zijn zijn de op dat moment aanwezige dependencies in de module waar de analyse op plaats heeft gevonden. De dependecyfiles worden ook opgeslagen om een periodieke analyse mogelijk te maken op de module die op dat moment bestaat.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    timeStamp & DateTime & naam van de module\\
    analyserTool & String & naam van de analyser tool\\
    analyserEngine & String & versie van de SCA tool die gebruikt is\\
    jenkinsBuildNr & Int & JenkinsBuildnr tracebility naar Jenkins\\
    gitHash & String & Githash van een analyseerde module Tracability naar Gitlab\\
    dependencies & Seq[String] & reverentie naar alle dependendencies in de module\\
    dependencyFiles & Seq[String] & reverentie naar alle dependencyFiles gedefinieerd in de module\\
\end{tabular}


\subsubsection{Dependency}\label{subsubsec:dependency}
De Dependency geeft informatie over de bewuste dependency weer waarbij er een referentie is naar een potentiele kwetsbaarheid.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    fileName & DateTime & naam van de module\\
    version & String & Naam van de analyser tool\\
    productName & String & Versie van de SCA tool die gebruikt is\\
    platform & Int & JenkinsBuildnr tracebility naar Jenkins\\
    description & String & Githash van  eanalyseerde module Tracability naar Gitlab\\
    vulnerabilities & Seq[String] & Reverentie naar alle dependendencies in de module.\\
\end{tabular}

\subsubsection{Vulberability}\label{subsubsec:vulberability}
Vulnerability geeft de informatie weer over een kwetsbaarheid waaronder het id en de ernst van de kwetsbaarheid. Waarbij het attribuut severity een samenvatting is van alle impact attributen.  De scores zijn opgebouwd middel het model dat door het nvd/nist is opgesteld

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\

    cveId & String & ID van de kwetsbaarheid\\
    source & String & de bron waar deze kwetsbaarheid is gevonden\\
    severity & String & algemene indicator van de ernst van de kwetsbaarheid \\
    attackVector & String & Op welke manier de kwetsbaarheid te benutten is\\
    description & String & Algemene beschrijving\\
    cveScore & Double & Algehele score van de kwetsbaarheid\\
    confidentialImpact & String & impact op confidentiality\\
    integrityImpact & String & impact op integrity \\
    availabilityImpact & String &  impact op availability  \\
    impactScore & DOuble & score van de impact door NVD  \\
    exploitabilityScore & Double & Score van exploitability door NVD  \\
    CWE & Seq[String]] & referentie naar de CWE \\
\end{tabular}

\subsubsection{CWE}\label{subsubsec:cwe}
De CWE's bevatten een url naar eventueel meer informatie over de kwetsbaarheid

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    cweID & String & Het ID van CWE die op mitre te vinden is.\\
    mitreURL & String & de url van de pagina op Mitre(gegenereerd)\\
\end{tabular}

\subsubsection{DependencyFiles}\label{subsubsec:dependencyFiles}
Om op een later stadium een periodieke analyse te kunnen doen worden de dependency files opgeslagen.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    project & String & Referentie naar Project\\
    module & String & Referentie naar module \\
    fileName & String & filename van het bestand \\
    partnerFile & Seq[String] & Reverentie naar andere benodigde bestanden.\\
    platform & String & gebruikte platform \\
    filePath & String & path naar het opgeslagen bestand \\ %TODO AAngepast
    nodeversion & String & versie van Node  \\
    npmversion & String & versie van NPM  \\
    sbtversion & String & versie van Version  \\
    scalaversion & String & versie van scala  \\
    javaversion & String & versie van java \\
\end{tabular}

\subsection{Portal Datamodel}\label{subsec:portal-datamodel}
Om de mogelijkheid te hebben om een samenvatting te verkrijgen over kwetsbaarheden per project, per module moet er in de portal een aantal etiteiten worden toegevoegd. Het ontwerp dat hier getoont is is dan ook een toevoeging op het bestaande model en zal dan ook niet in het geheel getoont worden maar alleen de aangegrenzende entiteiten en de aanpassingen hierop.

Voor de functionaliteit van de SOUP module binnen de portal moeten er twee entiteiten worden toegevoegd namelijk $'$Module$'$ voor het weergeven van module data in projecten en $'$VulnerabilitySummary$'$ waarin de de waarde worden opgeslagen die weergegeven worden in de portal. De keuze om deze gegevens toe te voegen in het datamodel van de Portal is performance. Vaak is het alleen van belang om de samenvatting te kunnen lezen en op het moment dat er teveel kwetsbaarheden gevonden worden kan er naar de details in de SOUPAPI worden gekeken. Om deze reden is het niet nodig om alle beschikbare info over te sturen gezien het in het geval van npm vaak in de honderden dependencies kan leiden.


\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/SOUPAPI-PortalDM}
    \caption{Toevoegingen op het bestaande portal Datamodel}
    \label{fig:SOUP-portalDm}
\end{figure}

\subsubsection{Project}\label{subsubsec:portalProject}
Dit is een bestaande entiteit binnen het huidige portal project. Hierin worden de gegevens opgeslagen die te maken hebben met de projecten die binnen Eaglescience bestaan. Dit zijn zowel Draft(nieuwe), active, en archived projecten.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    projectId & ProjectId > Long & uniek id\\
    status & ProjectStatus & [enum] status van het project\\
    customers & String & projectklant\\
    path & Option[String] & projectPath\\
    description & Option[String] & Bschrijving van het project\\
    creationDate & Date & aanmaakdatum van het project \\
    users & List[ProjectUser] & EagleScience medewerkers op het project \\ %TODO AAngepast
    workType & Option[WorkTypeType] & welk werk is er belegt in het project   \\
    ldapGroupDns & Option[List[String]] & Welke group heeft het project in LDAP  \\
    modules & Option[List[String]] & referentie naar de aanwezige modules  \\
\end{tabular}

\subsubsection{Module}\label{subsubsec:portalModule}
De module entiteit slaat de gegevens op voor een specifieke module. met een referentie naar een lijst van samenvatingen.

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    moduleId & ModuleId > Long & uniek id \\
    name & String & Referentie naar Project\\
    platform & String & gebruikte platform \\
    platformversion & String & versie van Node  \\
    framework & version & String & versie van NPM  \\
    frameworkVersion & String & versie van Version  \\
    declairedDepAmnt & Int & Aantal opgegeven dependencies\\
    totaalDepAmnt & Int & Totaal aantal dependencies.\\
    vulSummaries & Option[List[VulSumId]]& referentie naar Samenvatting\\
\end{tabular}

\subsubsection{VulnerabilitySummary}\label{subsubsec:portalVulSum}
Iedere moment dat er een analyse is uitgevoerd wordt er hier een samenvating aan toegevoegd

\begin{tabular}{lll}
    \textbf{Attribuut} & \textbf{Datatype} & \textbf{Notitie}\\
    vulSummaryId & VulSumId > Long & uniek Id\\
    timeStamp & DataTime & moment van opslaan van de samenvating\\
    details & String & referentie naar SOUPAPI model analyse\\
    severAmount & Int & aantal severe kwetsbaarheden\\
    highAmount & Int & aantal High kwetsbaarheden\\
    mediumAmount & Int & aantal Medium kwetsbaarheden\\
    lowAmount & Int & aantal Low kwetsbaarheden\\
\end{tabular}

\section{Algemene Architectuur}\label{sec:algemene-architectuur}
%TODO checken of 8pt leesbaar is op print
%TODO tekst beter structureren

Voor het analyseren, beheren en weergeven van een SOUP-analyse heeft de applicatie een aantal componenten nodig die elk een eigen verantwoordelijkheid hebben in de taken die de applicatie uit moet voeren. Om de verantwoordelijkheden te splitsen is de applicatie opgesplitst in verschillende modulen. Voor sommige onderdelen geldt zelfs dat weer een onderdeel in van een andere applicatie binnen de Eaglescience Dev-stack. Voor een volledige compatibiliteit wordt de applicatie in Scala geschreven waarbij het PlayFramework wordt gebruikt. Voor Frontend delen en dan met name wordt er gebruik gemaakt van de huidige portal wat dicteert dat Angular gebruikt gaat worden voor de ontwikkeling hiervan.


\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/umlet/exports/ApplicationComponents}
    \caption{Componenten SOUP Analyse Systeem}
    \label{fig:SOUP-Components}
\end{figure}
Zoals te zien is in figuur~\ref{fig:SOUP-Components} zijn er verschillende componenten die samen werken om een analyse weer te geven voor de gebruiker. \textbf{Jenkins} is verantwoordelijk voor het up-to-date houden van de laatste wijzigingen in de sourde-code en het initiele rapport. Welke aangeboden wordt aan de \textbf{SOUP-API}. Waarin de  \textbf{ReportParserEngine} verantwoordelijk is voor het omzetten van de binnegekomen rapporten naar het interne datamodel en het opslaan van de dependency declaraties. De \textbf{PeriodicAnalysisEngine} is verantwoordelijk voor het doen van periodieke analyses met de dependency declaraties. Centraal in de SOUP-API staat de \textbf{API} welke verantwoordelijk is voor de dataverwerking van de data die door de beide engines gegenereerd wordt of benodigd is. De \textbf{Portal} is verantwoordelijk voor de user interface met de gebruiker en de SOUP-API. Voor het periodiek kunnen analyseren van de modules binnen projecten is er een \textbf{AnalysisEnvironment} welke zorg draagt voor het veilig kunnen analyseren van modules op basis van de laatst opgeslagen dependencyDeclaraties. Als \textbf{Database} is MongoDB gekozen omdat er wisselingen in content kan zitten in de uitslagen en om deze reden en flexibelere manier van opslaan vereist is.

In de komende secties zal er dieper ingegaan worden op de verschillende componten waardoor er een completer beeld onstaat. Functionele ontwerpen zullen worden aangeboden in de hierop volgende hoofdstukken.

\section{SOUP API}\label{sec:soup-api}
De SOUP-API is een opzichzelf staand centraal deel van de applicatie dat verantwoordelijk is voor de verwerking van gegevens uit de SCA tooling en de portal. Als ook het regelen van de periodieke analyses om informatie up-to-date te houden van al eerder geanalyseerde projecten waar al een tijd geen wijzigingen op zijn geweest. Deze verantwoordelijkheden worden door de volgende componenten beheert

\subsection{ReportParseEngine}\label{subsec:reportparseengine}
De ReportParseEngine zorgt ervoor dat de binnenkomende datastroom vanuit de SCA tooling wordt verwerkt tot gegevens die in de SOAP-API gebruikt kan worden om inzichten in kwetsbaarheden te verkrijgen.

\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/umlet/exports/ReportParserComponents}
    \caption{Componenten SOUP-API ReportParser}
    \label{fig:SOUPAPIReportParserComps}
\end{figure}

De datastroom die binnenkomt bestaat uit een aantal zaken. Ten eerste is er het rapport dat uit de SCA tooling komt dat omgezet moet worden naar het intene datamodel. Daarnaast komen er vanuit het Jenkins process een aantal dependency declaraties mee die het mogelijk maken om in een later stadium de modules opnieuw te analyseren op kwetsbaarheden. Als laatst zal er metadata worden verstuurt die de API gebruikt om de analyses op de juiste plek op te slaan. Om de verantwoordelijkheden goed te verdelen zijn er een aantal services voorzien.

De \textbf{ParserService} is het centrale aanspreek punt van de ReportParserEngine en heeft als taak dat de juiste functionaliteit wordt aangesproken op het moment dat bepaalde vormen van instroom data wordt aangeboden. De ReportParserEngine moet de mogelijkheid hebben om in de toekomst met meer SCA tools op te kunnen gaan. De verwachting is dat niet iedere tool de zelfde opmaak van het rapport heeft en er om die redenen meerdere parsers moeten worden ontwikkeld in figuur ~\ref{fig:ReportParserComponents} staat deze aangegeven als $"$FutureParser$"$.

De \textbf{OWASP Parser} maakt het mogelijk om het rapport dat gegegeven wordt door in het hiervoor beschreven onderzoek geselecteerde SCA tool om te zetten naar data in de database. Naast het plaatsen van de data in de interne database genereert het ook een samenvating die in database van de portal wordt geplaatst.

\subsection{Periodic Analysis Engine}\label{subsec:periodicanalysisengine}
De Periodic Analysis Engine is een module dat verantwoordelijk is voor het periodiek analyseren van modulen. Een schematische weergave is te zien in figuur~\ref{fig:SOUPAPIPeriodicAnalysisEngineComps}. Deze modulen worden in een lijst genaamd de \textbf{scanQ} welke door de \textbf{scanQservice} wordt beheerd. Deze service is verantwoordelijk voor alle mutaties op de lijst als ook het ophalen van data welke bekend is voor de module om op die manier de Analyses Environment de juiste gegevens te versturen om aan analyses container op te kunnen zetten. De algehele controle wordt uitgevoerd door de \textbf{AnalysisController} welke verantwoordelijk is voor het starten van de gewenste analyse.

\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/umlet/exports/PeriodicAnalyisEngineComponents}
    \caption{Componenten SOUP-API Periodic Analysis Engine}
    \label{fig:SOUPAPIPeriodicAnalysisEngineComps}
\end{figure}

\newpage %TODO: Tijdelijk voor placering van de afbeeldingen later testen of zonder ook goed uitziet.
\subsection{API}\label{subsec:api2}
De voornaamste verantwoordelijkheid van de API is de zorg dat de data die in de SOUP-API wordt gemuteerd in de interne database opgeslagen wordt. Zie figuur ~\ref{fig:SOUPAPI-API comps}. Als ook de data in de database beschikbaar te stellen voor services en modulen die hier afhankelijk voor zijn. De API is opgebouwd volgens een Controller, Service Repository architectuur waarbij de Controller verantwoordelijk is voor het beschikbaar stellen van services op verschillende REST-endpoints. De Service verantwoordelijk is voor de business logic en mutatie van de data. Welke vervolgende door de Repository wordt weggeschreven naar de database.
\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/umlet/exports/API-ComponentsDiagram}
    \caption{Componenten API binndne de SOUPAPI}
    \label{fig:SOUPAPI-API comps}
\end{figure}

Naast services en een datacontrolle die verantwoordelijk is voor de mutatie van alle data. Is er ook een UploadCOntroller die samen met een reportService verantwoordelijk is voor het aansturen van de ReportParsingEngine. De reportService verwerkt ook de dependencyFiles die vanuit Jenkins wordt verstuurt.

\section{Software Compsition Analysis in Jenkins}\label{sec:jenkins}
De bestaande jenkins omgeving is de primaire bron voor nieuwe informatie uit projecten. Het aangewezen moment in de ontwikkeling is het moment dat er een acceptatie of productie build gedaan wordt, dit omdat op dit moment de dependencies relatief vast staan ten opzichte eerdere fasen in de ontwikkeling. Een andere reden is dat de development/ personal builds veel frequenter voorkomen en door de hieronder besproken toevoegingen de performance van deze builds achteruit kan gaan. In figuur ~\ref{fig:JenkinsSequece}


\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/umlet/exports/jenkinsBuildSequence}
    \caption{Jenkins Buildsequence: alleen onderdelen relavant voor SOUP-API worden getoont}
    \label{fig:JenkinsSequece}
\end{figure}

De pipeline binnen jenkins kent voor de SOUP API twee belangrijke momenten. In de \textbf{build/test fase} waarin de module wordt gebouwd en vervolgens getest zullen er twee toevoegingen gedaan moeten worden. Als eerst moet er meta data worden gepubliceerd op het filesysteem zodat er in een later stadium bekend is welke module, jenkins buildnummer en welke commit geanalyseerd wordt. Dit waarborgt de traceability tussen jenkins, gitlab en de SOUPAPI. Later moet in die zelfde stap de SCA tool worden uitgevoerd om de module te analyseren op kwetsbaarheden. Het result van deze analyse wordt vervolgens gepubliceerd op de filesystem.

Op het moment dat de \textbf{deploy} fase gelukt is. Kan er en upload plaatsvinden naar de SOUP API met daarin: "report.json, meta.json" en dependency declaraties als (build.sbt/dependencies.scala of de package-lock.json)
Als de upload gelukt dan zal jenkins de build vrij geven als geslaagd mocht er onverhoopt iets niet lukken in de upload zal dit te zien zijn in de logs van Jenkins.

\section{Portal}\label{sec:arch-portal} De portal is een inhouse applicatie welke gebruikt wordt voor administratieve zaken binnen het bedrijf. de wens is om hier functionaliteiten aan toe te voegen die bedrijfsbreed zijn en daarmee dus project oversteigend zijn. Voor deze applicatie dient er een module te worden toeegevoegd die fungeert als een interface waarin informatie over de bekende kwetsbaarheden te vinden is. maar ook instellingen kunnen worden. Er bestaat nu een module dat projects heet waarin verschillende details van het project in opgeslagen worden. samenvatingen van informatie over kwetsbaarheden kunnen hieraan worden toegevoegd.
Daarnaast zal er een nieuwe module moeten worden ontwikkeld waarin de details van de analyses zijn te vinden. Deze module moet samen werken met de SOUP-API API om de gewenste gegevens te kunnen weergeven. Ook de samenwerking tussen de portalmodulen Projects en SOUP api er zijn om vanuit een geselecteerd project de details in te kunnen zien.


\section{Analysis Environment}\label{sec:analysis-environment}
Deze omgeving moet het mogelijk maken om vanuit de SOUP API een analyse uit te voeren op modulen. waarbij er een docker container wordt gestart een analyse uitgevoerd wordt en vervolgens de container wordt vernietigd. de voornaamste reden is dat er door de opzet van npm/node en sbt/scala veel combinatie kunnen ontstaan die ervoor kunnen zorgen dat er de versies die gebruikt worden veranderen. Om deze reden moet de analyse omgevingen een nagenoeg exacte kopie zijn van de omgeving op productie. Naast de grote variatiet in omgevingen is er ook de mogelijkheid dat er ergens in een declaratie van dependencies code staat dat uitgevoerd kan worden middels install scripts. om ervoor te zorgen dat deze geen blijvend effect hebben op het systeem wordt er gekozen voor een docker systeem wat iedere keer opnieuw kan worden geinitiealiseerd.

\section{Deployment}\label{sec:deployment}


\begin{figure}[bth]
    \myfloatalign
    \includegraphics[width=10cm]{gfx/umlet/exports/deployment}
    \caption{Deployment }
    \label{fig:deployment}
\end{figure}

De portal draait lokaal binnen Eaglscience in een kubernetes omgeving. De frontend is geschreven in Angular 13. waarbij er tegen een backend wordt gecommuniceerd welke in Scala 2.13 is geschreven met PlayFramework. De SOUP-API is een opzich zelfstaand component binnen de gehele applicatie en zal ook worden geschreven in Scala met playFramework. De SOUP-API zal worden ondergebracht in een dockercontainer welk beschikbaar is voor de portal, jenkins en de database. De database is een mongoDB database en zal ook moeten worden voorzien. Het maakt voor de werking niet veel uit of dit een lokale Database of een instantie in de cloud is.

